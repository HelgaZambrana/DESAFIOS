{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API AlphaVantage - Intradiario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leer la contraseña y el token desde la variable de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z6Y4N8r40j\n"
     ]
    }
   ],
   "source": [
    "#my_host = config('DATABASE_MYHOST')\n",
    "#port = config('DATABASE_PORT')\n",
    "password = config('DATABASE_PASSWORD')\n",
    "#database_name = config('DATABASE_NAME')\n",
    "#user = config('DATABASE_USER')\n",
    "token = config('ALPHAVANTAGE_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definir la función para obtener datos de AlphaVantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIntra(symbol, interval, size): \n",
    "    function = 'TIME_SERIES_INTRADAY'\n",
    "    url = 'https://www.alphavantage.co/query'\n",
    "    parametros = {'function': function, 'symbol': symbol, 'interval': interval, 'outputsize': size, 'datatype': json, 'apikey': token}\n",
    "    \n",
    "    r = requests.get(url, params=parametros)\n",
    "    data = r.json()['Time Series ('+interval+')']\n",
    "    dataDF = pd.DataFrame.from_dict(data, orient='index') # Convertir a DataFrame\n",
    "    dataDF = dataDF.astype('float')\n",
    "    dataDF.index.name = 'Fecha'\n",
    "    dataDF.columns = ['Apertura', 'Maximo', 'Minimo', 'Cierre', 'Volumen']\n",
    "    dataDF = dataDF.sort_values('Fecha', ascending=True)\n",
    "    dataDF.index = pd.to_datetime(dataDF.index)\n",
    "    return dataDF\n",
    "\n",
    "acciones = ['AMZN', 'MELI', 'AAPL', 'GOOGL', 'MSFT'] # Lista de símbolos de acciones que se van a consultar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear e imprimir el Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Apertura  Maximo   Minimo   Cierre   Volumen Simbolo\n",
      "Fecha                                                                    \n",
      "2023-11-10 11:05:00   141.240  141.75  141.235  141.680  713530.0    AMZN\n",
      "2023-11-10 11:10:00   141.684  141.87  141.540  141.865  929114.0    AMZN\n",
      "2023-11-10 11:15:00   141.880  142.07  141.830  142.058  861128.0    AMZN\n",
      "2023-11-10 11:20:00   142.056  142.25  142.030  142.221  598445.0    AMZN\n",
      "2023-11-10 11:25:00   142.240  142.35  142.020  142.120  570369.0    AMZN\n",
      "...                       ...     ...      ...      ...       ...     ...\n",
      "2023-11-10 19:00:00   369.120  369.30  369.120  369.200     908.0    MSFT\n",
      "2023-11-10 19:05:00   369.300  369.35  369.200  369.250    1384.0    MSFT\n",
      "2023-11-10 19:10:00   369.390  369.42  369.150  369.150    1103.0    MSFT\n",
      "2023-11-10 19:15:00   369.220  369.35  369.150  369.250    1583.0    MSFT\n",
      "2023-11-10 19:20:00   369.350  369.35  369.350  369.350      30.0    MSFT\n",
      "\n",
      "[500 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "combined_data = pd.DataFrame() # Inicializar un DataFrame vacío para combinar los datos\n",
    "\n",
    "# Obtener y combinar los datos de las acciones en el DataFrame\n",
    "for accion in acciones:\n",
    "    data = getIntra(symbol=accion, interval='5min', size='compact')\n",
    "    data['Simbolo'] = accion # Agregar una columna para el símbolo de la acción\n",
    "    combined_data = pd.concat([combined_data, data])\n",
    "\n",
    "combined_data = combined_data.round(3) # Redondear los valores a tres decimales\n",
    "\n",
    "print(combined_data) # Imprimir el DataFrame combinado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conectarse con Amazon Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión a la base de datos exitosa\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(host=\"data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com\", port=5439, database=\"data-engineer-database\", user=\"hvzambrana_coderhouse\", password=password)\n",
    "    print(\"Conexión a la base de datos exitosa\")\n",
    "except Exception as e:\n",
    "    print(\"Error al crear la conexión\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear la tabla (si no existe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS hvzambrana_coderhouse.alphavantage (\n",
    "        simbolo VARCHAR(10) DISTKEY NOT NULL,\n",
    "        fecha TIMESTAMP SORTKEY NOT NULL,\n",
    "        apertura FLOAT(15) NULL,\n",
    "        maximo FLOAT(15) NULL,\n",
    "        minimo FLOAT(15) NULL,\n",
    "        cierre FLOAT(15) NULL,\n",
    "        volumen FLOAT(15) NULL\n",
    "    );\"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error al crear la tabla\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insertar los datos en la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros a insertar: 500\n",
      "Datos insertados con éxito\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    print(\"Número de registros a insertar:\", len(combined_data)) # Imprimir la cantidad de registros a insertar\n",
    "    \n",
    "    for index, row in combined_data.iterrows():\n",
    "        try:\n",
    "            cur.execute(\"\"\"\n",
    "            INSERT INTO hvzambrana_coderhouse.alphavantage (simbolo, fecha, apertura, maximo, minimo, cierre, volumen)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s);\"\"\",\n",
    "            (row['Simbolo'], index, row['Apertura'], row['Maximo'], row['Minimo'], row['Cierre'], row['Volumen']))\n",
    "\n",
    "        except psycopg2.IntegrityError as e:\n",
    "            print(f\"Registro duplicado para fecha {index}. No se ha insertado.\")\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Datos insertados con éxito\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error al insertar datos\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cerrar la conexión a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
